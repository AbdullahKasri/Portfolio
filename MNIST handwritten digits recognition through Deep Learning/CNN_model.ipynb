{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset is a widely-used benchmark dataset for image classification, particularly in the field of computer vision and deep learning. It consists of a collection of 70,000 grayscale images of handwritten digits, each of which is 28x28 pixels in size. The images are divided into a training set of 60,000 examples and a test set of 10,000 examples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape the training and testing sets to fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the input shape for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the class vectors to binary class matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the data to have values between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rhe shapes of the training and testing sets and their sample sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape: ', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the batch size, number of classes, and number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 50"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a sequential model and add layers to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = (3, 3), activation = 'relu', input_shape = input_shape))\n",
    "model.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation = 'softmax'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model with the specified loss function, optimizer, and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.categorical_crossentropy, optimizer = keras.optimizers.Adadelta(), metrics = ['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define an image data generator for data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rotation_range = 10, zoom_range = 0.1, width_shift_range = 0.1, height_shift_range = 0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model using the data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "468/468 [==============================] - 219s 469ms/step - loss: 2.2960 - accuracy: 0.1171 - val_loss: 2.2701 - val_accuracy: 0.1613\n",
      "Epoch 2/50\n",
      "468/468 [==============================] - 206s 441ms/step - loss: 2.2703 - accuracy: 0.1574 - val_loss: 2.2276 - val_accuracy: 0.2359\n",
      "Epoch 3/50\n",
      "468/468 [==============================] - 172s 368ms/step - loss: 2.2424 - accuracy: 0.1922 - val_loss: 2.1777 - val_accuracy: 0.3186\n",
      "Epoch 4/50\n",
      "468/468 [==============================] - 197s 422ms/step - loss: 2.2098 - accuracy: 0.2271 - val_loss: 2.1187 - val_accuracy: 0.3939\n",
      "Epoch 5/50\n",
      "468/468 [==============================] - 203s 433ms/step - loss: 2.1716 - accuracy: 0.2624 - val_loss: 2.0485 - val_accuracy: 0.5157\n",
      "Epoch 6/50\n",
      "468/468 [==============================] - 199s 426ms/step - loss: 2.1269 - accuracy: 0.2950 - val_loss: 1.9658 - val_accuracy: 0.6172\n",
      "Epoch 7/50\n",
      "468/468 [==============================] - 201s 429ms/step - loss: 2.0741 - accuracy: 0.3291 - val_loss: 1.8702 - val_accuracy: 0.6733\n",
      "Epoch 8/50\n",
      "468/468 [==============================] - 179s 381ms/step - loss: 2.0141 - accuracy: 0.3612 - val_loss: 1.7635 - val_accuracy: 0.7082\n",
      "Epoch 9/50\n",
      "468/468 [==============================] - 206s 439ms/step - loss: 1.9539 - accuracy: 0.3869 - val_loss: 1.6513 - val_accuracy: 0.7274\n",
      "Epoch 10/50\n",
      "468/468 [==============================] - 185s 394ms/step - loss: 1.8887 - accuracy: 0.4091 - val_loss: 1.5392 - val_accuracy: 0.7383\n",
      "Epoch 11/50\n",
      "468/468 [==============================] - 200s 426ms/step - loss: 1.8263 - accuracy: 0.4272 - val_loss: 1.4307 - val_accuracy: 0.7457\n",
      "Epoch 12/50\n",
      "468/468 [==============================] - 191s 408ms/step - loss: 1.7687 - accuracy: 0.4398 - val_loss: 1.3300 - val_accuracy: 0.7556\n",
      "Epoch 13/50\n",
      "468/468 [==============================] - 200s 426ms/step - loss: 1.7146 - accuracy: 0.4563 - val_loss: 1.2393 - val_accuracy: 0.7641\n",
      "Epoch 14/50\n",
      "468/468 [==============================] - 220s 470ms/step - loss: 1.6662 - accuracy: 0.4691 - val_loss: 1.1574 - val_accuracy: 0.7712\n",
      "Epoch 15/50\n",
      "468/468 [==============================] - 219s 468ms/step - loss: 1.6250 - accuracy: 0.4793 - val_loss: 1.0865 - val_accuracy: 0.7770\n",
      "Epoch 16/50\n",
      "468/468 [==============================] - 204s 436ms/step - loss: 1.5891 - accuracy: 0.4890 - val_loss: 1.0257 - val_accuracy: 0.7820\n",
      "Epoch 17/50\n",
      "468/468 [==============================] - 221s 473ms/step - loss: 1.5516 - accuracy: 0.4981 - val_loss: 0.9728 - val_accuracy: 0.7889\n",
      "Epoch 18/50\n",
      "468/468 [==============================] - 250s 533ms/step - loss: 1.5215 - accuracy: 0.5071 - val_loss: 0.9260 - val_accuracy: 0.7938\n",
      "Epoch 19/50\n",
      "468/468 [==============================] - 268s 572ms/step - loss: 1.4902 - accuracy: 0.5148 - val_loss: 0.8859 - val_accuracy: 0.7986\n",
      "Epoch 20/50\n",
      "468/468 [==============================] - 257s 548ms/step - loss: 1.4628 - accuracy: 0.5248 - val_loss: 0.8493 - val_accuracy: 0.8048\n",
      "Epoch 21/50\n",
      "468/468 [==============================] - 230s 491ms/step - loss: 1.4428 - accuracy: 0.5336 - val_loss: 0.8183 - val_accuracy: 0.8099\n",
      "Epoch 22/50\n",
      "468/468 [==============================] - 247s 527ms/step - loss: 1.4229 - accuracy: 0.5379 - val_loss: 0.7915 - val_accuracy: 0.8134\n",
      "Epoch 23/50\n",
      "468/468 [==============================] - 213s 456ms/step - loss: 1.4069 - accuracy: 0.5420 - val_loss: 0.7668 - val_accuracy: 0.8195\n",
      "Epoch 24/50\n",
      "468/468 [==============================] - 223s 477ms/step - loss: 1.3818 - accuracy: 0.5518 - val_loss: 0.7429 - val_accuracy: 0.8232\n",
      "Epoch 25/50\n",
      "468/468 [==============================] - 198s 423ms/step - loss: 1.3695 - accuracy: 0.5523 - val_loss: 0.7228 - val_accuracy: 0.8256\n",
      "Epoch 26/50\n",
      "468/468 [==============================] - 190s 406ms/step - loss: 1.3520 - accuracy: 0.5591 - val_loss: 0.7040 - val_accuracy: 0.8299\n",
      "Epoch 27/50\n",
      "468/468 [==============================] - 194s 415ms/step - loss: 1.3427 - accuracy: 0.5604 - val_loss: 0.6885 - val_accuracy: 0.8334\n",
      "Epoch 28/50\n",
      "468/468 [==============================] - 286s 611ms/step - loss: 1.3246 - accuracy: 0.5685 - val_loss: 0.6723 - val_accuracy: 0.8356\n",
      "Epoch 29/50\n",
      "468/468 [==============================] - 307s 655ms/step - loss: 1.3124 - accuracy: 0.5733 - val_loss: 0.6576 - val_accuracy: 0.8408\n",
      "Epoch 30/50\n",
      "468/468 [==============================] - 306s 654ms/step - loss: 1.2995 - accuracy: 0.5786 - val_loss: 0.6438 - val_accuracy: 0.8427\n",
      "Epoch 31/50\n",
      "468/468 [==============================] - 279s 596ms/step - loss: 1.2878 - accuracy: 0.5827 - val_loss: 0.6303 - val_accuracy: 0.8462\n",
      "Epoch 32/50\n",
      "468/468 [==============================] - 227s 485ms/step - loss: 1.2792 - accuracy: 0.5840 - val_loss: 0.6188 - val_accuracy: 0.8488\n",
      "Epoch 33/50\n",
      "468/468 [==============================] - 222s 473ms/step - loss: 1.2627 - accuracy: 0.5895 - val_loss: 0.6073 - val_accuracy: 0.8508\n",
      "Epoch 34/50\n",
      "468/468 [==============================] - 224s 478ms/step - loss: 1.2517 - accuracy: 0.5933 - val_loss: 0.5964 - val_accuracy: 0.8529\n",
      "Epoch 35/50\n",
      "468/468 [==============================] - 198s 423ms/step - loss: 1.2443 - accuracy: 0.5960 - val_loss: 0.5860 - val_accuracy: 0.8556\n",
      "Epoch 36/50\n",
      "468/468 [==============================] - 208s 445ms/step - loss: 1.2345 - accuracy: 0.5991 - val_loss: 0.5764 - val_accuracy: 0.8583\n",
      "Epoch 37/50\n",
      "468/468 [==============================] - 220s 471ms/step - loss: 1.2199 - accuracy: 0.6048 - val_loss: 0.5653 - val_accuracy: 0.8612\n",
      "Epoch 38/50\n",
      "468/468 [==============================] - 201s 430ms/step - loss: 1.2098 - accuracy: 0.6084 - val_loss: 0.5568 - val_accuracy: 0.8639\n",
      "Epoch 39/50\n",
      "468/468 [==============================] - 200s 427ms/step - loss: 1.2043 - accuracy: 0.6111 - val_loss: 0.5491 - val_accuracy: 0.8652\n",
      "Epoch 40/50\n",
      "468/468 [==============================] - 200s 427ms/step - loss: 1.1961 - accuracy: 0.6132 - val_loss: 0.5407 - val_accuracy: 0.8685\n",
      "Epoch 41/50\n",
      "468/468 [==============================] - 206s 440ms/step - loss: 1.1814 - accuracy: 0.6163 - val_loss: 0.5329 - val_accuracy: 0.8684\n",
      "Epoch 42/50\n",
      "468/468 [==============================] - 195s 417ms/step - loss: 1.1793 - accuracy: 0.6191 - val_loss: 0.5236 - val_accuracy: 0.8717\n",
      "Epoch 43/50\n",
      "468/468 [==============================] - 218s 466ms/step - loss: 1.1592 - accuracy: 0.6242 - val_loss: 0.5163 - val_accuracy: 0.8719\n",
      "Epoch 44/50\n",
      "468/468 [==============================] - 223s 475ms/step - loss: 1.1504 - accuracy: 0.6294 - val_loss: 0.5081 - val_accuracy: 0.8743\n",
      "Epoch 45/50\n",
      "468/468 [==============================] - 225s 480ms/step - loss: 1.1525 - accuracy: 0.6284 - val_loss: 0.5025 - val_accuracy: 0.8754\n",
      "Epoch 46/50\n",
      "468/468 [==============================] - 212s 452ms/step - loss: 1.1386 - accuracy: 0.6336 - val_loss: 0.4963 - val_accuracy: 0.8761\n",
      "Epoch 47/50\n",
      "468/468 [==============================] - 240s 512ms/step - loss: 1.1328 - accuracy: 0.6371 - val_loss: 0.4890 - val_accuracy: 0.8790\n",
      "Epoch 48/50\n",
      "468/468 [==============================] - 209s 448ms/step - loss: 1.1221 - accuracy: 0.6387 - val_loss: 0.4828 - val_accuracy: 0.8801\n",
      "Epoch 49/50\n",
      "468/468 [==============================] - 205s 438ms/step - loss: 1.1161 - accuracy: 0.6392 - val_loss: 0.4770 - val_accuracy: 0.8813\n",
      "Epoch 50/50\n",
      "468/468 [==============================] - 207s 442ms/step - loss: 1.1100 - accuracy: 0.6416 - val_loss: 0.4709 - val_accuracy: 0.8830\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(datagen.flow(x_train, y_train, batch_size = batch_size), steps_per_epoch = len(x_train) // batch_size, epochs = epochs, verbose = 1, validation_data = (x_test, y_test), workers = -1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  0.47090741991996765\n",
      "Test accuracy:  0.8830000162124634\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose = 0)\n",
    "print('Test loss: ', score[0])\n",
    "print('Test accuracy: ', score[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An accuracy rate of 88% is astounding for a computer vision model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, this model is ready for deployment on any classufication project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mnist.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a bonus, I decided to make a GUI where you can draw a number and get a prediction on it.\n",
    "\n",
    "Check 'GUI.py'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thanks for reading !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
